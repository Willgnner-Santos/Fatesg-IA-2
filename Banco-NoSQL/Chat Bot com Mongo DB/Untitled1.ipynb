{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1764468276979,
     "user": {
      "displayName": "Maria Clara Fernandes",
      "userId": "09020035651108157996"
     },
     "user_tz": 180
    },
    "id": "mWniD6LwaYv_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiag\\Downloads\\trabalho_maria\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 30273,
     "status": "error",
     "timestamp": 1764468307256,
     "user": {
      "displayName": "Maria Clara Fernandes",
      "userId": "09020035651108157996"
     },
     "user_tz": 180
    },
    "id": "09dARZ0JajNl",
    "outputId": "679fc644-7c6c-4a24-fcba-4748772b137e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão ao MongoDB estabelecida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#CONEXÃO\n",
    "\n",
    "try:\n",
    "    # Conectar ao MongoDB\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    # Testar a conexão\n",
    "    client.server_info()\n",
    "    print(\"Conexão ao MongoDB estabelecida com sucesso!\")\n",
    "except pymongo.errors.ConnectionError:\n",
    "    print(\"ERRO: Não foi possível conectar ao MongoDB. Certifique-se de que o serviço MongoDB está rodando na porta 27017.\")\n",
    "    # Se não conectar, o script não deve continuar\n",
    "    exit()\n",
    "\n",
    "db = client[\"chatbot\"]\n",
    "collection = db[\"conversas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "aborted",
     "timestamp": 1764468307302,
     "user": {
      "displayName": "Maria Clara Fernandes",
      "userId": "09020035651108157996"
     },
     "user_tz": 180
    },
    "id": "yq6poHf9awiX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o modelo 'facebook/opt-1.3b' (pode demorar na primeira vez)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiag\\Downloads\\trabalho_maria\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\thiag\\.cache\\huggingface\\hub\\models--facebook--opt-1.3b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=101) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando resposta para: 'O que é MongoDB?'\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURAÇÃO E GERAÇÃO DE TEXTO\n",
    "\n",
    "# Criar um pipeline para geração de texto usando um modelo da Hugging Face\n",
    "print(\"Carregando o modelo 'facebook/opt-1.3b' (pode demorar na primeira vez)...\")\n",
    "modelo = pipeline(\"text-generation\", model=\"facebook/opt-1.3b\")\n",
    "\n",
    "# Definir a pergunta que será enviada para o modelo de IA\n",
    "pergunta = \"O que é MongoDB?\"\n",
    "\n",
    "# Gerar resposta usando o modelo de IA\n",
    "print(f\"Gerando resposta para: '{pergunta}'\")\n",
    "# Gerar a resposta\n",
    "resposta = modelo(pergunta, max_length=100, do_sample=True)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1764468307314,
     "user": {
      "displayName": "Maria Clara Fernandes",
      "userId": "09020035651108157996"
     },
     "user_tz": 180
    },
    "id": "fqcu6_Iha6sx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Resposta armazenada com sucesso!\n",
      "Pergunta: O que é MongoDB?\n",
      "Resposta:\n",
      " O que é MongoDB?\n",
      "\n",
      "O MongoDB é um sistema de dados que é usado em diversas empresas para atender aos requisitos mais específicos dos clientes e as necessidades de sua empresa. A tecnologia foi lançada em 2008, e desde então se tornou mais popular por sua potência de informação e sua capacidade de oferecer um bom serviço de dados.\n",
      "\n",
      "Mais informações\n",
      "\n",
      "Como funciona?\n",
      "\n",
      "O MongoDB é um sistema de dados que permite que a empresa pode se tornar mais flexível e o que a empresa precisa de um sistema de dados. O sistema de dados é um sistema de dados que permite que a empresa pode se tornar mais flexível e o que a empresa precisa de um sistema de dados. A tecnologia foi lançada em 2008, e desde então se tornou mais popular por sua pot\n"
     ]
    }
   ],
   "source": [
    "#ARMAZENAMENTO E EXIBIÇÃO\n",
    "\n",
    "# Armazenar a pergunta e resposta no banco de dados MongoDB\n",
    "collection.insert_one({\n",
    "    \"pergunta\": pergunta,\n",
    "    \"resposta\": resposta\n",
    "})\n",
    "\n",
    "# Exibir mensagem de sucesso no terminal\n",
    "print(\"-\" * 40)\n",
    "print(\"Resposta armazenada com sucesso!\")\n",
    "\n",
    "# Exibir a pergunta e a resposta gerada no terminal\n",
    "print(\"Pergunta:\", pergunta)\n",
    "print(\"Resposta:\\n\", resposta)\n",
    "\n",
    "# Fechar a conexão com o MongoDB ao final\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1764468307316,
     "user": {
      "displayName": "Maria Clara Fernandes",
      "userId": "09020035651108157996"
     },
     "user_tz": 180
    },
    "id": "gzO9xYbZboYJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=201) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PROMPT PARA GERAÇÃO DE PERGUNTAS:\n",
      "Com base em um banco de dados de funcionários que possui os campos 'nome', 'cargo', 'idade' e 'salario', crie 3 perguntas relevantes para análise de dados.\n",
      "\n",
      "PERGUNTAS GERADAS PELA IA:\n",
      "Com base em um banco de dados de funcionários que possui os campos 'nome', 'cargo', 'idade' e 'salario', crie 3 perguntas relevantes para análise de dados.\n",
      "\n",
      "Os dados foram colados em diferentes sistemas de computação, mas todos têm um nome semelhante.\n",
      "\n",
      "O Banco Central (BC) apresentou ainda hoje (26) um relatório sobre as informações de dados do banco de dados.\n",
      "\n",
      "O relatório foi elaborado pelo BC, com base em um plano de desenvolvimento digital que está a ser implementado pelo banco central.\n",
      "\n",
      "A reportagem do site \"Vizinho e Correio Brasil\" apurou que o relatório é a primeira reportagem do plano e será distribuído em meio ao ano.\n",
      "\n",
      "Depois de uma iniciativa do Banco Central, o Banco Central divulgou na última sexta-feira (29) um plano de desenvolvimento digital para a economia brasileira, que está em fase de desenvolvimento digital.\n",
      "\n",
      "A reportagem do site \"Viz\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "#PROMPT DO CHAT\n",
    "# modelo_iml = pipeline(\"text-generation\", model=\"facebook/opt-iml-1.3b\")\n",
    "modelo_iml = modelo # Usando o mesmo modelo da primeira parte, se o IML não for estritamente necessário.\n",
    "\n",
    "# Prompt de Engenharia para gerar perguntas\n",
    "prompt_perguntas = \"Com base em um banco de dados de funcionários que possui os campos 'nome', 'cargo', 'idade' e 'salario', crie 3 perguntas relevantes para análise de dados.\"\n",
    "\n",
    "# Gerar as perguntas\n",
    "perguntas_geradas = modelo_iml(\n",
    "    prompt_perguntas,\n",
    "    max_length=200, # Aumente o tamanho para caber mais perguntas\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PROMPT PARA GERAÇÃO DE PERGUNTAS:\")\n",
    "print(prompt_perguntas)\n",
    "print(\"\\nPERGUNTAS GERADAS PELA IA:\")\n",
    "print(perguntas_geradas)\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGWPlySfgbXrJCnS0iEqUG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
